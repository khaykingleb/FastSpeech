{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3noMHgyWV4m"
      },
      "source": [
        "# Text-to-Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6FStR-eWV86"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/khaykingleb/Text-to-Speech.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot0z3Dc6WV89"
      },
      "source": [
        "%cd Text-to-Speech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hSysv2vWV89"
      },
      "source": [
        "Download the neccessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7jw7lB-WV8_"
      },
      "source": [
        "%%bash\n",
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWxEfpLvWepJ"
      },
      "source": [
        "import json\n",
        "\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "from tts.vocoders import WaveGlow\n",
        "from tts.models import FastSpeech\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = \"svg\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFW9SmbzWV9A"
      },
      "source": [
        "Download the LJSpeech data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aNODaFZWV9B"
      },
      "source": [
        "%%bash\n",
        "mkdir ./data\n",
        "mkdir ./saved\n",
        "mkdir ./pretrained\n",
        "wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2 -O ./data/LJSpeech-1.1.tar.bz2\n",
        "tar -C ./data -xjf ./data/LJSpeech-1.1.tar.bz2\n",
        "rm ./data/LJSpeech-1.1.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMAZrCYmWV9C"
      },
      "source": [
        "Download the vocoder â€” WaveGlove."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5jKeKEPWV9D"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/NVIDIA/waveglow.git\n",
        "pip install googledrivedownloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFPYHAzLWV9D"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4RfdwiWV9G"
      },
      "source": [
        "gdd.download_file_from_google_drive(\n",
        "    file_id=\"1rpK8CzAAirq9sWZhe9nlfvxMF1dRgFbF\",\n",
        "    dest_path=\"./waveglow_256channels_universal_v5.pt\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHLWIGYUWV9L"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLiql9XtWV9M"
      },
      "source": [
        "%run main.py -c configs/config.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIFSpyXhWV9M"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPe51zMMWV9N"
      },
      "source": [
        "def pronounce_audio(\n",
        "    text: str, \n",
        "    tokenizer: nn.Module,\n",
        "    model: nn.Module,\n",
        "    vocoder: nn.Module,\n",
        "    sr: int = 22050,\n",
        "    alpha: float = 1.0,\n",
        "):  \n",
        "    model.eval()\n",
        "    tokens, token_lengths = tokenizer(text)\n",
        "    durations, melspec = model.inference(tokens, alpha)\n",
        "    \n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.imshow(melspec[0].detach().numpy())\n",
        "    plt.xlabel(\"Time Frame\")\n",
        "    plt.ylabel(\"Frequency (Hz)\")\n",
        "    plt.title(\"Melspectrogram\")\n",
        "    plt.grid()\n",
        "\n",
        "    wav = vocoder.inference(melspec)\n",
        "    if wav.dim() == 2:\n",
        "        wav = wav.mean(dim=0)\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.plot(wav, alpha=0.7, c=\"green\")\n",
        "    plt.xlabel(\"Time\", size=16)\n",
        "    plt.ylabel(\"Amplitude\", size=16)\n",
        "    plt.show()\n",
        "    \n",
        "    display.display(display.Audio(wav, rate=sr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js2sW18OhVeU"
      },
      "source": [
        "Download the pretrained model (summer-water-119 in wandb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pofr1poYWV9N"
      },
      "source": [
        "%%bash\n",
        "wget https://www.dropbox.com/s/bby35ib9p7aq6o6/best_paper_1.pt?dl=0 \\\n",
        "    -O checkpoint.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tiWncfFWV9N"
      },
      "source": [
        "with open(\"configs/config.json\") as file:\n",
        "    config = json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHJry6M1WV9O"
      },
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = torchaudio.pipelines \\\n",
        "    .TACOTRON2_GRIFFINLIM_CHAR_LJSPEECH \\\n",
        "    .get_text_processor()\n",
        "model = FastSpeech(config).to(DEVICE)\n",
        "vocoder = WaveGlow().eval().to(DEVICE)\n",
        "\n",
        "checkpoint = torch.load(\"checkpoint.pt\", map_location=DEVICE)\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIOxFNeNWV9Q"
      },
      "source": [
        "examlpes = [\n",
        "    \"A defibrillator is a device that gives a high energy electric shock \" \n",
        "    \"to the heart of someone who is in cardiac arrest\",\n",
        "    \"Massachusetts Institute of Technology may be best known for its \"\n",
        "    \"math, science and engineering education\",\n",
        "    \"Wasserstein distance or Kantorovich Rubinstein metric is a distance \"\n",
        "    \"function defined between probability distributions on a given metric space\"\n",
        "]\n",
        "\n",
        "for example in examlpes:\n",
        "    pronounce_audio(example, tokenizer, model, vocoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fht5kd1IWV9V"
      },
      "source": [
        "## Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swK9idPLBQCS"
      },
      "source": [
        "[Link](https://wandb.ai/khaykingleb/tts_one_batch/reports/FastSpeech--VmlldzoxMzA3MDY5)"
      ]
    }
  ]
}